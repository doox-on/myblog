---
title: 4. (LLM) Model Comparison
feature_image: "https://picsum.photos/2560/600?image=1024"
---

Week 5~6's focus was on evaluating and comparing finetuned models across different translation stages.

After training separate NL->JSON, JSON->SQL, and direct NL->SQL models using ~500 triplets, each was tested using the same given evaluation pipeline.
The results showed that finetuned models generally outperformed the Groq baseline, though the direct NL->SQL model achieved slightly higher accuracy due to overfitting to familiar data.
This highlighted the need to generate a new, unseen dataset for fair generalization testing in the upcoming phase.

<ul style="font-size: 1.6rem; line-height: 1.6; text-align: center; margin: 0;">
  <li style="list-style: none; margin: 0px 0;">
    <a href="https://github.com/doox-on/CS4220_NORP" 
       style="font-size: 1.3rem; text-decoration: none;">
      Main Project Github Repo
    </a>
  </li>
</ul>

---


### 1. Model Fine Tuning with Llama 3.1

I fine tuned the models using the “meta-llama/Llama-3.1-8b” base model. Each was trained on 500 structured triplets to form a complete NL->JSON->SQL reasoning pipeline.

{% include figure.html image="assets/norp4-1.png" caption="Meta llama setup" %}


This approach allowed the model to learn structured reasoning patterns rather than just memorizing syntax. 

{% include figure.html image="assets/norp4-2.png" caption="3 different fine tuned models" %}

---

### 2. NL->JSON->SQL Evaluation Results

The NL->JSON->SQL pipeline showed higher accuracy than the Groq NL->SQL baseline.
However, the direct NL->SQL fine tuned model achieved slightly better scores on the same dataset!
Probably due to overfitting, since it was trained and tested on identical data samples.


{% include figure.html image="assets/norp4-3.png" caption="Groq NL->SQL" %}
{% include figure.html image="assets/norp4-4.png" caption="Finetuned NL->JSON->SQL" %}
{% include figure.html image="assets/norp4-5.png" caption="Finetuned NL->SQL" %}

These results indicate that while the intermediate JSON step improves reasoning consistency,
a new unseen dataset is needed to fairly measure its true generalization benefits.



---




### Next Steps (Week 7~8)

- Create a new unseen dataset to evaluate whether the NL->JSON->SQL pipeline generalizes beyond the training data.
- Conduct a structured comparison between Groq NL->SQL, NL->SQL, and NL->JSON->SQL to measure true performance differences.
- Analyze reasoning behavior to determine if the JSON intermediate step contributes to more interpretable and consistent SQL generation.
  
