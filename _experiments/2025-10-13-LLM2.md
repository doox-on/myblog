---
title: 2. (LLM) NL->JSON->SQL
feature_image: "https://picsum.photos/2560/600?image=1024"
---

During the first two weeks, I focused on understanding the original **NL2SQL agent** from the NORP repository and building the foundation for a new **SQL -> JSON plan generator**.

The goal was to create structured intermediate data that an LLM can later learn from — instead of directly jumping into “NL -> SQL”, I started by **reversing the problem** and teaching the model to reason from existing SQL queries first.

<ul style="font-size: 1.6rem; line-height: 1.6; text-align: center; margin: 0;">
  <li style="list-style: none; margin: 0px 0;">
    <a href="https://github.gatech.edu/asreeraj3/iec-norp-llm?tab=readme-ov-file#2-local-finetuned-model-conversion" 
       style="font-size: 1.3rem; text-decoration: none;">
      The Original Repo
    </a>
  </li>
</ul>

---

### Transition to SQL -> JSON Plans

Originally, the plan was to extract query plans from DuckDB via EXPLAIN (FORMAT JSON),
but it did not support that feature yet.
I replaced it with an **LLM based JSON planner** using Groq’s API. 

This new pipeline takes in an SQL query and produces a **structured JSON plan** that outlines:
- The sequence of operations (Projection, Filter, Sort, Join, etc.)
- Their conditions or parameters
- The hierarchical structure of the query


{% include figure.html image="assets/norp2-1.png" title="Example:SQL -> JSON test" %}



---

### Why This Step Matters

This stage isn’t about fancy UI or multimodal input, it’s about creating a reliable internal structure.
By giving the LLM a consistent JSON schema, we make its reasoning interpretable, verifiable, and trainable.

This step also mirrors the motivation behind NL2Weld:
the idea that an intermediate structured representation (IR) helps bridge natural language and executable logic.

---

### Technology Stack

* **LLM Integration** – Groq API (production model: `llama-3.1-8b-instant`)  
* **Prompting Techniques** – ReAct pipeline for query decomposition + refinement  
* **Database** – SQLite with generated tables from CSV data  
* **Evaluation** – SQL -> JSON
* **Supporting Tools** – data augmentation with paraphrased NLQs  

---
