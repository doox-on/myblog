---
title: CPU vs GPU (CUDA)
feature_image: "https://picsum.photos/2560/600?image=1024"
---

CUDA is the most common programming toolkit for parallel programming.
I tried to do some basic comparison to see GPU is actually faster than CPU in some specific cases.
This experiment handles a large size of array, so could be a good example. 



<ul style="font-size: 1.6rem; line-height: 1.6; text-align: center; margin: 0;">
  <li style="list-style: none; margin: 0px 0;">
    <a href="https://gist.github.com/doox-on/f1dbdd5daa3fcd35f89b2e6a1392db03" 
       style="font-size: 1.3rem; text-decoration: none;">
      CUDA Repo
    </a>
  </li>
</ul>

### Overview

The idea of program itself is simple.
Make a large array, and shift the number in the array for each index.

1. Test size of arrays with 2^10 ~ 2^24.
2. For a better result, run 20 times and get the average.
3. Then see when the GPU runs faster than CPU

--- 
### Hardware Setup

- 8 core CPU each 4 GB in ICE Cluster
- Tesla V100-PCIE-32GB. 

---
### Result

For GPU running time, [Malloc GPU mem + memcpy CPU->GPU, Kernel processing, memcpy GPU->CPU] are included.
Each time GPU kernel launches, I Malloced, memcpyed, and freed the test array for better testing (warm up).
Run 20 times, num_elements range is (1<<10 ~ 1<<24).



```text
exp GPU ms 	CPU ms	GPU us	CPU us	log (GPU us)	log (CPU us)
10	2.345	0	    2345	0	    3.370142847	    #NUM!
11	2.425	0	    2425	0	    3.384711743	    #NUM!
12	2.39	0.04	2390	40	    3.378397901	    1.602059991
13	2.435	0.1	    2435	100	    3.386498966	    2
14	2.45	0.22	2450	220	    3.389166084	    2.342422681
15	3.785	0.275	3785	275	    3.578065884	    2.439332694
16	2.64	0.985	2640	985	    3.421603927	    2.99343623
17	2.89	1.24	2890	1240	3.460897843	    3.093421685
18	3.21	2.505	3210	2505	3.506505032	    3.39880773
19	3.49	7.16	3490	7160	3.542825427	    3.854913022
20	4.51	11.255	4510	11255	3.654176542	    4.051345499
21	6.195	27.835	6195	27835	3.792041311	    4.444591226
22	10.235	43.45	10235	43450	4.010087847	    4.637989781
23	18.25	100.655	18250	100655	4.261262869	    5.002835353
24	34.26	180.34	34260	180340	4.534787359	    5.256092065
```
{% include figure.html image="assets/CUDA_1_1.png" title="CPU vs GPU" %}

The orange dots are GPU and the blues are CPU data.
X axis : time (us)
Y axis : exp number of elements. 

Two trendlines intersect at (19.1643,3.7811), which means that around 2^19 elements of int(4bytes), GPU gets faster than CPU. 
So total 4 * 2^19 btyes is the point for this experiments. 



---
### Closing thought

Since I assumed the CPU doesn't have any fixed constant to run the code(which isn't right), but this can be a good overview to understand overall CUDA Programming.
I will see if different dimensions or datatype could effect the runtime. 

